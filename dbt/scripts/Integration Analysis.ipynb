{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4189864c-ff8b-4fcd-8d19-c86cf5193e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.use(\"pgf\")\n",
    "mpl.rcParams.update({\n",
    "    \"pgf.texsystem\": \"lualatex\",\n",
    "    # \"pgf.preamble\": \"\\n\".join([\n",
    "    #      r\"\\usepackage[utf8x]{inputenc}\",\n",
    "    #      r\"\\usepackage[T1]{fontenc}\",\n",
    "    # ]),\n",
    "})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.cm as cm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use([\"science\", \"no-latex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689f0c29-1b9a-4a3e-8d79-76f84d430da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_data_sizes = {\n",
    "    \"sentence_creation\": {\n",
    "        1: range(1, 8434380+1, 8434380 // step_size + 1),\n",
    "        2: range(1, 2024422+1, 2024422 // step_size + 1),\n",
    "        3: range(1, 850446+1, 850446 // step_size + 1),\n",
    "        4: range(1, 468156+1, 468156 // step_size + 1),\n",
    "        5: range(1, 288195+1, 288195 // step_size + 1),\n",
    "        6: range(1, 251544+1, 251544 // step_size + 1),\n",
    "        7: range(1, 175714+1, 175714 // step_size + 1),\n",
    "        8: range(1, 141016+1, 141016 // step_size + 1),\n",
    "        9: range(1, 109665+1, 109665 // step_size + 1),\n",
    "        10: range(1, 88940+1, 88940 // step_size + 1),\n",
    "    },\n",
    "    \"sentence_consolidation\": {\n",
    "        1: range(1, 8434380+1, 8434380 // step_size + 1),\n",
    "        2: range(1, 2024422+1, 2024422 // step_size + 1),\n",
    "        3: range(1, 850446+1, 850446 // step_size + 1),\n",
    "        4: range(1, 468156+1, 468156 // step_size + 1),\n",
    "        5: range(1, 288195+1, 288195 // step_size + 1),\n",
    "        6: range(1, 251544+1, 251544 // step_size + 1),\n",
    "        7: range(1, 175714+1, 175714 // step_size + 1),\n",
    "        8: range(1, 141016+1, 141016 // step_size + 1),\n",
    "        9: range(1, 109665+1, 109665 // step_size + 1),\n",
    "        10: range(1, 88940+1, 88940 // step_size + 1),\n",
    "    },\n",
    "    \"probability_dictionary_creation\": {\n",
    "        1: range(1, 8434380+1, 8434380 // step_size + 1),\n",
    "        2: range(1, 2024422+1, 2024422 // step_size + 1),\n",
    "        3: range(1, 850446+1, 850446 // step_size + 1),\n",
    "        4: range(1, 468156+1, 468156 // step_size + 1),\n",
    "        5: range(1, 288195+1, 288195 // step_size + 1),\n",
    "        6: range(1, 251544+1, 251544 // step_size + 1),\n",
    "        7: range(1, 175714+1, 175714 // step_size + 1),\n",
    "        8: range(1, 141016+1, 141016 // step_size + 1),\n",
    "        9: range(1, 109665+1, 109665 // step_size + 1),\n",
    "        10: range(1, 88940+1, 88940 // step_size + 1),\n",
    "    },\n",
    "    \"probability_calculation\": {\n",
    "        1: range(1, 274648+1, 274648 // step_size + 1),\n",
    "        2: range(1, 75262+1, 75262 // step_size + 1),\n",
    "        3: range(1, 22380+1, 22380 // step_size + 1),\n",
    "        4: range(1, 29064+1, 29064 // step_size + 1),\n",
    "        5: range(1, 11070+1, 11070 // step_size + 1),\n",
    "        6: range(1, 17214+1, 17214 // step_size + 1),\n",
    "        7: range(1, 3759+1, 3759 // step_size + 1),\n",
    "        8: range(1, 9304+1, 9304 // step_size + 1),\n",
    "        9: range(1, 3519+1, 3519 // step_size + 1),\n",
    "        10: range(1, 4380+1, 4380 // step_size + 1),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7325772f-ee67-4cba-97a5-0779772d6a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets = [\"postgres\", \"databricks\"]\n",
    "targets = [\"databricks\"]\n",
    "# experiments = [\"sentence_creation\", \"sentence_consolidation\", \"probability_dictionary_creation\", \"probability_calculation\"]\n",
    "experiments = [\"sentence_creation\", \"sentence_consolidation\"]\n",
    "\n",
    "experiment_results = {}\n",
    "\n",
    "for target in targets:\n",
    "    experiment_results[target] = {}\n",
    "    for experiment in experiments:\n",
    "        with open(f\"../experiment_results/{target}/{experiment}/execution_times.pkl\", \"rb\") as file:\n",
    "            execution_times = pickle.load(file)\n",
    "        experiment_results[target][experiment] = execution_times\n",
    "\n",
    "experiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8bdd74-bf2e-4569-af0b-5ffa23dcc12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    \"sentence_creation\": \"Sentence Creation\",\n",
    "    \"sentence_consolidation\": \"Sentence Consolidation\",\n",
    "    \"probability_dictionary_creation\": \"Prob. Dict. Creation\",\n",
    "    \"probability_calculation\": \"Prob. Calculation\",\n",
    "}\n",
    "\n",
    "def get_label(dataset):\n",
    "    return labels[dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf709a7a-3378-4ea2-a60f-c3596bf90628",
   "metadata": {},
   "source": [
    "## Over Data Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f056493-f89d-46f3-b1a4-50c56167fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_data_size = 500_000\n",
    "mycmap = cm.viridis\n",
    "\n",
    "def plot_over_data_size(ax, execution_times, experiment, cluster_sizes):\n",
    "    norm = plt.Normalize(vmin=np.min(cluster_sizes), vmax=np.max(cluster_sizes))\n",
    "    \n",
    "    color = None\n",
    "    for cluster_size in cluster_sizes:\n",
    "        times = execution_times[cluster_size]\n",
    "        \n",
    "        data_sizes = np.array(experiments_data_sizes[experiment][cluster_size])\n",
    "        data_sizes = data_sizes[data_sizes <= max_data_size]\n",
    "        times = times[0:len(data_sizes)]\n",
    "\n",
    "        ax.plot(data_sizes, times, color=mycmap(norm(cluster_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6f4429-0da7-4150-90a4-cf9bec7dd9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for target in targets:\n",
    "    for experiment in experiments:\n",
    "        plt.tight_layout()\n",
    "        fig, ax = plt.subplots(figsize=(4,3))\n",
    "        \n",
    "        execution_times = experiment_results[target][experiment]\n",
    "\n",
    "        cluster_sizes = np.arange(1, 11)\n",
    "        plot_over_data_size(ax, execution_times, experiment, cluster_sizes)\n",
    "            \n",
    "        #draw_timeout(ax, resize=False)\n",
    "        #draw_legend(ax, \"Experiment\", resize=False, loc=\"best\")\n",
    "        sm = plt.cm.ScalarMappable(\n",
    "            cmap=mycmap,\n",
    "            norm=plt.Normalize(vmin=np.min(cluster_sizes), vmax=np.max(cluster_sizes))\n",
    "        )\n",
    "        fig.colorbar(sm, ax=ax, label=\"Cluster Size\")\n",
    "        ax.set_title(get_label(experiment))\n",
    "        ax.set_ylabel(\"Computation Time (Seconds)\")\n",
    "        ax.set_xlabel(\"Data Size (Rows)\")\n",
    "        \n",
    "        display(fig)\n",
    "        plt.savefig(f\"../figures/integration_data_sizes_{target}_{experiment}.pgf\", bbox_inches=\"tight\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee054042-79a9-4941-a076-a292165e3ac8",
   "metadata": {},
   "source": [
    "## Over Cluster Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeed4f5-a69d-457a-9cda-da625318cf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size_range = np.arange(10_000, 110_000, 10_000)\n",
    "\n",
    "def plot_over_cluster_size(ax, execution_times, experiment, cluster_sizes, data_size):\n",
    "    norm = plt.Normalize(vmin=np.min(data_size_range), vmax=np.max(data_size_range))\n",
    "    \n",
    "    interps = [\n",
    "        interp1d(\n",
    "            experiments_data_sizes[experiment][cluster_size],\n",
    "            execution_times[cluster_size],\n",
    "            kind='linear',\n",
    "            bounds_error=False,\n",
    "            fill_value=\"extrapolate\"\n",
    "        )\n",
    "        for cluster_size in cluster_sizes\n",
    "    ]\n",
    "    y = [f(data_size) for f in interps]\n",
    "\n",
    "    ax.plot(cluster_sizes, y, color=mycmap(norm(data_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14488446-66a8-4a3e-9e1a-828187ef413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for target in targets:\n",
    "    for experiment in experiments:\n",
    "        plt.tight_layout()\n",
    "        fig, ax = plt.subplots(figsize=(4,3))\n",
    "        \n",
    "        execution_times = experiment_results[target][experiment]\n",
    "\n",
    "        cluster_sizes = np.arange(1, 11)\n",
    "\n",
    "        for data_size in data_size_range:\n",
    "            plot_over_cluster_size(ax, execution_times, experiment, cluster_sizes, data_size)\n",
    "            \n",
    "        #draw_timeout(ax, resize=False)\n",
    "        #draw_legend(ax, \"Experiment\", resize=False, loc=\"best\")\n",
    "        sm = plt.cm.ScalarMappable(\n",
    "            cmap=mycmap,\n",
    "            norm=plt.Normalize(vmin=np.min(data_size_range), vmax=np.max(data_size_range))\n",
    "        )\n",
    "        fig.colorbar(sm, ax=ax, label=\"Data Size (Rows)\")\n",
    "        ax.set_title(get_label(experiment))\n",
    "        ax.set_ylabel(\"Computation Time (Seconds)\")\n",
    "        ax.set_xlabel(\"Cluster Size\")\n",
    "        ax.set_ylim(bottom=0)\n",
    "        #\n",
    "        display(fig)\n",
    "        plt.savefig(f\"../figures/integration_cluster_sizes_{target}_{experiment}.pgf\", bbox_inches=\"tight\")\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
